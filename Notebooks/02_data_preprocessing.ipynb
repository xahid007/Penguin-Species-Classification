{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset and prepare the training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>FEMALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen              39.1             18.7              181.0   \n",
       "1  Adelie  Torgersen              39.5             17.4              186.0   \n",
       "2  Adelie  Torgersen              40.3             18.0              195.0   \n",
       "3  Adelie  Torgersen               NaN              NaN                NaN   \n",
       "4  Adelie  Torgersen              36.7             19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  \n",
       "0       3750.0    MALE  \n",
       "1       3800.0  FEMALE  \n",
       "2       3250.0  FEMALE  \n",
       "3          NaN     NaN  \n",
       "4       3450.0  FEMALE  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Dataset/penguins_size.csv')\n",
    "df = df[df['sex'] != '.'] #There is a row where sex = '.', so filtering it out\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (343, 6)\n",
      "Shape of y: (343,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['species'])\n",
    "y  = df.species\n",
    "print('Shape of X:', X.shape)\n",
    "print('Shape of y:', y.shape)\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "num_features = X.select_dtypes(include='number').columns.tolist()\n",
    "cat_features = X.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missinng value Handeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species               0\n",
       "island                0\n",
       "culmen_length_mm      2\n",
       "culmen_depth_mm       2\n",
       "flipper_length_mm     2\n",
       "body_mass_g           2\n",
       "sex                  10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach for handelling missing value:\n",
    "\n",
    "1. For the `sex` column (categorical feature), replace any missing values with the most frequently occurring value (the mode).\n",
    "2. For the remaining numerical features with missing values, use the average value (mean) of each respective column to fill in the gaps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach:**\n",
    "- Apply one-hot encoding to categorical columns (`Sex`, `island`, and `species`) because these columns do not have an inherent order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define preprocessing for numerical features (with KNN imputation)\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),  # Use KNN imputation for numerical features\n",
    "    ('scaler', StandardScaler())  # Scale numerical features\n",
    "])\n",
    "\n",
    "# Define preprocessing for categorical features\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values with mode\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', drop='first'))  # Encode categorical features\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps for numerical and categorical features\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, num_features),\n",
    "    ('cat', categorical_pipeline, cat_features)\n",
    "])\n",
    "\n",
    "# Define models with pipelines\n",
    "pipelines = {\n",
    "    'Logistic Regression': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', LogisticRegression(max_iter=1000, n_jobs=-1, class_weight='balanced'))\n",
    "    ]),\n",
    "    'Decision Tree': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', DecisionTreeClassifier(class_weight='balanced'))\n",
    "    ]),\n",
    "    'Random Forest': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', RandomForestClassifier(n_jobs=-1, class_weight='balanced'))\n",
    "    ]),\n",
    "    'Support Vector Machine': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', SVC(class_weight='balanced'))\n",
    "    ]),\n",
    "    'Naive Bayes': Pipeline([\n",
    "        ('preprocessor', ColumnTransformer([\n",
    "            ('num', SimpleImputer(strategy='mean'), num_features),  # Skip scaling for Naive Bayes\n",
    "            ('cat', categorical_pipeline, cat_features)\n",
    "        ])),\n",
    "        ('model', GaussianNB())\n",
    "    ]),\n",
    "    'Gradient Boosting': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', GradientBoostingClassifier())\n",
    "    ]),\n",
    "    'AdaBoost': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', AdaBoostClassifier())\n",
    "    ]),\n",
    "    'Bagging': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', BaggingClassifier(n_jobs=-1))\n",
    "    ]),\n",
    "    'K-Nearest Neighbors': Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', KNeighborsClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Initialize metrics dictionary\n",
    "metrics = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1 Score': []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Metrics:\n",
      "                    Model  Accuracy  Precision    Recall  F1 Score\n",
      "0     Logistic Regression  0.992727   0.993007  0.992727  0.992663\n",
      "1           Decision Tree  0.963636   0.964105  0.963636  0.963455\n",
      "2           Random Forest  0.981818   0.982134  0.981818  0.981691\n",
      "3  Support Vector Machine  0.992727   0.993007  0.992727  0.992663\n",
      "4             Naive Bayes  0.901347   0.937892  0.901347  0.904475\n",
      "5       Gradient Boosting  0.974545   0.975674  0.974545  0.974200\n",
      "6                AdaBoost  0.926936   0.934856  0.926936  0.928665\n",
      "7                 Bagging  0.978182   0.978896  0.978182  0.978005\n",
      "8     K-Nearest Neighbors  0.985387   0.986307  0.985387  0.985412\n",
      "\n",
      "Test Set Evaluation for Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Adelie       1.00      0.97      0.98        30\n",
      "   Chinstrap       0.93      1.00      0.97        14\n",
      "      Gentoo       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           0.99        69\n",
      "   macro avg       0.98      0.99      0.98        69\n",
      "weighted avg       0.99      0.99      0.99        69\n",
      "\n",
      "Confusion Matrix for Logistic Regression:\n",
      "[[29  1  0]\n",
      " [ 0 14  0]\n",
      " [ 0  0 25]]\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation for each pipeline\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Use stratified cross-validation\n",
    "for name, pipeline in pipelines.items():\n",
    "    scores = cross_validate(pipeline, X_train, y_train, cv=cv, scoring=['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted'])\n",
    "    metrics['Model'].append(name)\n",
    "    metrics['Accuracy'].append(scores['test_accuracy'].mean())\n",
    "    metrics['Precision'].append(scores['test_precision_weighted'].mean())\n",
    "    metrics['Recall'].append(scores['test_recall_weighted'].mean())\n",
    "    metrics['F1 Score'].append(scores['test_f1_weighted'].mean())\n",
    "\n",
    "# Create DataFrame from metrics\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(\"Cross-Validation Metrics:\")\n",
    "print(metrics_df)\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "best_model_name = metrics_df.loc[metrics_df['Accuracy'].idxmax()]['Model']\n",
    "best_model = pipelines[best_model_name]\n",
    "best_model.fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(f\"\\nTest Set Evaluation for {best_model_name}:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix for the best model\n",
    "print(f\"Confusion Matrix for {best_model_name}:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Feature importance for interpretable models\n",
    "if hasattr(best_model.named_steps['model'], 'feature_importances_'):\n",
    "    feature_importances = best_model.named_steps['model'].feature_importances_\n",
    "    feature_names = best_model.named_steps['preprocessor'].transformers_[1][1].named_steps['encoder'].get_feature_names_out(cat_features).tolist()\n",
    "    feature_names += num_features\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "    print(\"\\nFeature Importances:\")\n",
    "    print(importance_df.sort_values(by='Importance', ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
